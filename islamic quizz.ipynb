{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526b982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbe8ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df1 = pd.read_csv('C:/Users/damia/OneDrive/Bureau/dataset1.csv')\n",
    "df2 = pd.read_csv('C:/Users/damia/OneDrive/Bureau/dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b16fa494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>من كان أول خليفة بعد النبي محمد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ما هي أركان الإسلام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ما هي السورة الأولى في القرآن الكريم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>من هو النبي الذي بُعث إلى بني إسرائيل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ما هي كفارة من أفطر عمداً في نهار رمضان</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id                            Question_text\n",
       "0            1          من كان أول خليفة بعد النبي محمد\n",
       "1            2                      ما هي أركان الإسلام\n",
       "2            3     ما هي السورة الأولى في القرآن الكريم\n",
       "3            4    من هو النبي الذي بُعث إلى بني إسرائيل\n",
       "4            5  ما هي كفارة من أفطر عمداً في نهار رمضان"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba417263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_text</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>السورة رقم 2 في القرآن</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>السورة الثانية في القرآن</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>ثاني سورة في القرآن</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>أطول سورة في القرآن الكريم هي سورة البقرة</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>البقرة</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id              Question_text  \\\n",
       "0            9  ما هي أطول سورة في القران   \n",
       "1            9  ما هي أطول سورة في القران   \n",
       "2            9  ما هي أطول سورة في القران   \n",
       "3            9  ما هي أطول سورة في القران   \n",
       "4            9  ما هي أطول سورة في القران   \n",
       "\n",
       "                                     answers score  \n",
       "0                     السورة رقم 2 في القرآن   0.5  \n",
       "1                   السورة الثانية في القرآن   0.5  \n",
       "2                        ثاني سورة في القرآن   0.5  \n",
       "3  أطول سورة في القرآن الكريم هي سورة البقرة     1  \n",
       "4                                     البقرة     1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the datasets \n",
    "df= pd.merge(df1,df2,on='Question_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07eea6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_text</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>747.000000</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ما هي أقصر سورة في القرآن</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>696</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.768407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.660639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Question_id              Question_text answers score\n",
       "count    747.000000                        747     747   746\n",
       "unique          NaN                          9      43   414\n",
       "top             NaN  ما هي أقصر سورة في القرآن       1     1\n",
       "freq            NaN                        113     696    39\n",
       "mean      12.768407                        NaN     NaN   NaN\n",
       "std        2.660639                        NaN     NaN   NaN\n",
       "min        9.000000                        NaN     NaN   NaN\n",
       "25%       10.000000                        NaN     NaN   NaN\n",
       "50%       13.000000                        NaN     NaN   NaN\n",
       "75%       15.000000                        NaN     NaN   NaN\n",
       "max       17.000000                        NaN     NaN   NaN"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returning a statistical summary about the dataset\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70796ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prétraitement des données en utilisant NLTK de NLP\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a41dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation, déviser le texte en une séquence de tokens\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Replace NaN values with an empty string\n",
    "df['answers']=df['answers'].fillna('')\n",
    "# Convert lists to strings\n",
    "df['answers'] = df['answers'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "# Apply tokenization\n",
    "df['answers'] = df['answers'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb560216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [السورة, رقم, 2, في, القرآن]\n",
       "1                        [السورة, الثانية, في, القرآن]\n",
       "2                             [ثاني, سورة, في, القرآن]\n",
       "3    [أطول, سورة, في, القرآن, الكريم, هي, سورة, الب...\n",
       "4                                             [البقرة]\n",
       "Name: answers, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd31192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ء',\n",
       " 'ءَ',\n",
       " 'آ',\n",
       " 'آب',\n",
       " 'آذار',\n",
       " 'آض',\n",
       " 'آمينَ',\n",
       " 'آناء',\n",
       " 'آنفا',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'آهاً',\n",
       " 'آهٍ',\n",
       " 'آهِ',\n",
       " 'آي',\n",
       " 'أ',\n",
       " 'أبدا',\n",
       " 'أبريل',\n",
       " 'أبو',\n",
       " 'أبٌ',\n",
       " 'أجل',\n",
       " 'أجمع',\n",
       " 'أحد',\n",
       " 'أخبر',\n",
       " 'أخذ',\n",
       " 'أخو',\n",
       " 'أخٌ',\n",
       " 'أربع',\n",
       " 'أربعاء',\n",
       " 'أربعة',\n",
       " 'أربعمئة',\n",
       " 'أربعمائة',\n",
       " 'أرى',\n",
       " 'أسكن',\n",
       " 'أصبح',\n",
       " 'أصلا',\n",
       " 'أضحى',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'أعلم',\n",
       " 'أغسطس',\n",
       " 'أف',\n",
       " 'أفريل',\n",
       " 'أفعل به',\n",
       " 'أفٍّ',\n",
       " 'أقبل',\n",
       " 'أقل',\n",
       " 'أكتوبر',\n",
       " 'أكثر',\n",
       " 'أل',\n",
       " 'ألا',\n",
       " 'ألف',\n",
       " 'ألفى',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أمام',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'أمسى',\n",
       " 'أمّا',\n",
       " 'أن',\n",
       " 'أنا',\n",
       " 'أنبأ',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'أنتِ',\n",
       " 'أنشأ',\n",
       " 'أنى',\n",
       " 'أنًّ',\n",
       " 'أنّى',\n",
       " 'أهلا',\n",
       " 'أو',\n",
       " 'أوت',\n",
       " 'أوشك',\n",
       " 'أول',\n",
       " 'أولئك',\n",
       " 'أولاء',\n",
       " 'أولالك',\n",
       " 'أوه',\n",
       " 'أوّهْ',\n",
       " 'أى',\n",
       " 'أي',\n",
       " 'أيا',\n",
       " 'أيار',\n",
       " 'أيضا',\n",
       " 'أيلول',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'أيها',\n",
       " 'أيّ',\n",
       " 'أيّان',\n",
       " 'أُفٍّ',\n",
       " 'ؤ',\n",
       " 'إحدى',\n",
       " 'إذ',\n",
       " 'إذا',\n",
       " 'إذاً',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'إزاء',\n",
       " 'إلا',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'إليكنّ',\n",
       " 'إليكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إلّا',\n",
       " 'إما',\n",
       " 'إمّا',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'إنَّ',\n",
       " 'إى',\n",
       " 'إي',\n",
       " 'إياك',\n",
       " 'إياكم',\n",
       " 'إياكما',\n",
       " 'إياكن',\n",
       " 'إيانا',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهم',\n",
       " 'إياهما',\n",
       " 'إياهن',\n",
       " 'إياي',\n",
       " 'إيه',\n",
       " 'إيهٍ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ابتدأ',\n",
       " 'اتخذ',\n",
       " 'اثنا',\n",
       " 'اثنان',\n",
       " 'اثني',\n",
       " 'اثنين',\n",
       " 'اخلولق',\n",
       " 'اربعون',\n",
       " 'اربعين',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'الآن',\n",
       " 'الألاء',\n",
       " 'الألى',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللائي',\n",
       " 'اللاتي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'انبرى',\n",
       " 'انقلب',\n",
       " 'ب',\n",
       " 'بؤسا',\n",
       " 'بئس',\n",
       " 'باء',\n",
       " 'بات',\n",
       " 'بخ',\n",
       " 'بخٍ',\n",
       " 'بس',\n",
       " 'بسّ',\n",
       " 'بضع',\n",
       " 'بطآن',\n",
       " 'بعد',\n",
       " 'بعدا',\n",
       " 'بعض',\n",
       " 'بغتة',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بيد',\n",
       " 'بين',\n",
       " 'بَسْ',\n",
       " 'بَلْهَ',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'تاء',\n",
       " 'تارة',\n",
       " 'تاسع',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تبدّل',\n",
       " 'تجاه',\n",
       " 'تحت',\n",
       " 'تحوّل',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تسع',\n",
       " 'تسعة',\n",
       " 'تسعمئة',\n",
       " 'تسعمائة',\n",
       " 'تسعون',\n",
       " 'تسعين',\n",
       " 'تشرين',\n",
       " 'تعسا',\n",
       " 'تعلَّم',\n",
       " 'تفعلان',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'تلقاء',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'تموز',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'تَيْنِ',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'ث',\n",
       " 'ثاء',\n",
       " 'ثالث',\n",
       " 'ثامن',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثلاث',\n",
       " 'ثلاثاء',\n",
       " 'ثلاثة',\n",
       " 'ثلاثمئة',\n",
       " 'ثلاثمائة',\n",
       " 'ثلاثون',\n",
       " 'ثلاثين',\n",
       " 'ثم',\n",
       " 'ثمان',\n",
       " 'ثمانمئة',\n",
       " 'ثمانون',\n",
       " 'ثماني',\n",
       " 'ثمانية',\n",
       " 'ثمانين',\n",
       " 'ثمة',\n",
       " 'ثمنمئة',\n",
       " 'ثمَّ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ج',\n",
       " 'جانفي',\n",
       " 'جعل',\n",
       " 'جلل',\n",
       " 'جمعة',\n",
       " 'جميع',\n",
       " 'جنيه',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'جير',\n",
       " 'جيم',\n",
       " 'ح',\n",
       " 'حاء',\n",
       " 'حادي',\n",
       " 'حار',\n",
       " 'حاشا',\n",
       " 'حاي',\n",
       " 'حبذا',\n",
       " 'حبيب',\n",
       " 'حتى',\n",
       " 'حجا',\n",
       " 'حدَث',\n",
       " 'حرى',\n",
       " 'حزيران',\n",
       " 'حسب',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'حمو',\n",
       " 'حمٌ',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'حيَّ',\n",
       " 'حَذارِ',\n",
       " 'خ',\n",
       " 'خاء',\n",
       " 'خاصة',\n",
       " 'خال',\n",
       " 'خامس',\n",
       " 'خبَّر',\n",
       " 'خلا',\n",
       " 'خلافا',\n",
       " 'خلف',\n",
       " 'خمس',\n",
       " 'خمسة',\n",
       " 'خمسمئة',\n",
       " 'خمسمائة',\n",
       " 'خمسون',\n",
       " 'خمسين',\n",
       " 'خميس',\n",
       " 'د',\n",
       " 'دال',\n",
       " 'درهم',\n",
       " 'درى',\n",
       " 'دواليك',\n",
       " 'دولار',\n",
       " 'دون',\n",
       " 'دونك',\n",
       " 'ديسمبر',\n",
       " 'دينار',\n",
       " 'ذ',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذال',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذانِ',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذهب',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذيت',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ذَيْنِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ر',\n",
       " 'رأى',\n",
       " 'راء',\n",
       " 'رابع',\n",
       " 'راح',\n",
       " 'رجع',\n",
       " 'رزق',\n",
       " 'رويدك',\n",
       " 'ريال',\n",
       " 'ريث',\n",
       " 'رُبَّ',\n",
       " 'ز',\n",
       " 'زاي',\n",
       " 'زعم',\n",
       " 'زود',\n",
       " 'س',\n",
       " 'ساء',\n",
       " 'سابع',\n",
       " 'سادس',\n",
       " 'سبت',\n",
       " 'سبتمبر',\n",
       " 'سبحان',\n",
       " 'سبع',\n",
       " 'سبعة',\n",
       " 'سبعمئة',\n",
       " 'سبعمائة',\n",
       " 'سبعون',\n",
       " 'سبعين',\n",
       " 'ست',\n",
       " 'ستة',\n",
       " 'ستمئة',\n",
       " 'ستمائة',\n",
       " 'ستون',\n",
       " 'ستين',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سرعان',\n",
       " 'سقى',\n",
       " 'سمعا',\n",
       " 'سنتيم',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'سين',\n",
       " 'ش',\n",
       " 'شباط',\n",
       " 'شبه',\n",
       " 'شتان',\n",
       " 'شتانَ',\n",
       " 'شرع',\n",
       " 'شمال',\n",
       " 'شيكل',\n",
       " 'شين',\n",
       " 'شَتَّانَ',\n",
       " 'ص',\n",
       " 'صاد',\n",
       " 'صار',\n",
       " 'صباح',\n",
       " 'صبر',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'صهٍ',\n",
       " 'صهْ',\n",
       " 'ض',\n",
       " 'ضاد',\n",
       " 'ضحوة',\n",
       " 'ط',\n",
       " 'طاء',\n",
       " 'طاق',\n",
       " 'طالما',\n",
       " 'طرا',\n",
       " 'طفق',\n",
       " 'طَق',\n",
       " 'ظ',\n",
       " 'ظاء',\n",
       " 'ظلّ',\n",
       " 'ظنَّ',\n",
       " 'ع',\n",
       " 'عاد',\n",
       " 'عاشر',\n",
       " 'عامة',\n",
       " 'عجبا',\n",
       " 'عدا',\n",
       " 'عدَّ',\n",
       " 'عسى',\n",
       " 'عشر',\n",
       " 'عشرة',\n",
       " 'عشرون',\n",
       " 'عشرين',\n",
       " 'عل',\n",
       " 'علق',\n",
       " 'علم',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'علًّ',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'عوض',\n",
       " 'عيانا',\n",
       " 'عين',\n",
       " 'عَدَسْ',\n",
       " 'غ',\n",
       " 'غادر',\n",
       " 'غالبا',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'غير',\n",
       " 'غين',\n",
       " 'ف',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فاء',\n",
       " 'فبراير',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'فلا',\n",
       " 'فلان',\n",
       " 'فلس',\n",
       " 'فمن',\n",
       " 'فو',\n",
       " 'فوق',\n",
       " 'في',\n",
       " 'فيفري',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'ق',\n",
       " 'قاطبة',\n",
       " 'قاف',\n",
       " 'قام',\n",
       " 'قبل',\n",
       " 'قد',\n",
       " 'قرش',\n",
       " 'قطّ',\n",
       " 'قلما',\n",
       " 'ك',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأنّ',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'كاد',\n",
       " 'كاف',\n",
       " 'كان',\n",
       " 'كانون',\n",
       " 'كثيرا',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كرب',\n",
       " 'كسا',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كلَّا',\n",
       " 'كلّما',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كن',\n",
       " 'كى',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'كِخ',\n",
       " 'ل',\n",
       " 'لئن',\n",
       " 'لا',\n",
       " 'لا سيما',\n",
       " 'لات',\n",
       " 'لاسيما',\n",
       " 'لام',\n",
       " 'لبيك',\n",
       " 'لدن',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لعلَّ',\n",
       " 'لعمر',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكنَّ',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لمّا',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'ليت',\n",
       " 'ليرة',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'م',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ما',\n",
       " 'ما أفعله',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مائة',\n",
       " 'مادام',\n",
       " 'ماذا',\n",
       " 'مارس',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ماي',\n",
       " 'مايو',\n",
       " 'متى',\n",
       " 'مثل',\n",
       " 'مذ',\n",
       " 'مرّة',\n",
       " 'مساء',\n",
       " 'مع',\n",
       " 'معاذ',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'مكانَك',\n",
       " 'مليم',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منذ',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'ميم',\n",
       " 'ن',\n",
       " 'نا',\n",
       " 'نبَّا',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'نفس',\n",
       " 'نوفمبر',\n",
       " 'نون',\n",
       " 'نيسان',\n",
       " 'نيف',\n",
       " 'نَخْ',\n",
       " 'نَّ',\n",
       " 'ه',\n",
       " 'هؤلاء',\n",
       " 'ها',\n",
       " 'هاء',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاكَ',\n",
       " 'هاهنا',\n",
       " 'هبّ',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هللة',\n",
       " 'هلم',\n",
       " 'هلّا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'همزة',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'هيّا',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَجْ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذَيْنِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَيْهات',\n",
       " 'و',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'وا',\n",
       " 'واحد',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'واهاً',\n",
       " 'واو',\n",
       " 'وجد',\n",
       " 'وراءَك',\n",
       " 'ورد',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهب',\n",
       " 'وهو',\n",
       " 'وَيْ',\n",
       " 'وُشْكَانَ',\n",
       " 'ى',\n",
       " 'ي',\n",
       " 'يا',\n",
       " 'ياء',\n",
       " 'يفعلان',\n",
       " 'يفعلون',\n",
       " 'يمين',\n",
       " 'ين',\n",
       " 'يناير',\n",
       " 'يوان',\n",
       " 'يورو',\n",
       " 'يوليو',\n",
       " 'يونيو',\n",
       " 'ّأيّان'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('Arabic'))\n",
    "stop_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dacc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answers'] = df['answers'].apply(lambda x: [w for w in x if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "121fa37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_id</th>\n",
       "      <th>Question_text</th>\n",
       "      <th>answers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>[السورة, رقم, 2, القرآن]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>[السورة, الثانية, القرآن]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>[سورة, القرآن]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>[أطول, سورة, القرآن, الكريم, سورة, البقرة]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>ما هي أطول سورة في القران</td>\n",
       "      <td>[البقرة]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_id              Question_text  \\\n",
       "0            9  ما هي أطول سورة في القران   \n",
       "1            9  ما هي أطول سورة في القران   \n",
       "2            9  ما هي أطول سورة في القران   \n",
       "3            9  ما هي أطول سورة في القران   \n",
       "4            9  ما هي أطول سورة في القران   \n",
       "\n",
       "                                      answers score  \n",
       "0                    [السورة, رقم, 2, القرآن]   0.5  \n",
       "1                   [السورة, الثانية, القرآن]   0.5  \n",
       "2                              [سورة, القرآن]   0.5  \n",
       "3  [أطول, سورة, القرآن, الكريم, سورة, البقرة]     1  \n",
       "4                                    [البقرة]     1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization & stemming\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Stem words in answers column\n",
    "df['answers'] = df['answers'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatize words in answers column\n",
    "df['answers'] = df['answers'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ef2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodage des mots \n",
    "#création de modèle\n",
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(df['answers'], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "024cb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#véctoriser les réponses \n",
    "max_len = model.vector_size\n",
    "\n",
    "W = np.zeros((len(df['answers']), max_len))\n",
    "for i, sentence in enumerate(df['answers']):\n",
    "    word_vectors = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            word_vectors.append(model.wv[word])\n",
    "    if len(word_vectors) > 0:\n",
    "        mean_vector = np.mean(word_vectors, axis=0)\n",
    "        W[i, :] = mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd0870f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, 'سورة': 1, 'القرآن': 2, 'البقرة': 3, 'الكوثر': 4, 'كانت': 5, 'السورة': 6, 'النبي': 7, 'أسية': 8, 'الكريم': 9, 'تكبر': 10, 'اسم': 11, 'اقصر': 12, 'عشرةعاما': 13, '0.5': 14, 'فرعون': 15, 'زوجة': 16, 'بخمس': 17, 'سنة': 18, 'ب15': 19, 'هوأسية': 20, 'أطول': 21, 'الثانية': 22, 'الكوثرهي': 23, 'أقصر': 24, ':': 25, '2': 26, 'رقم': 27, 'اطول': 28, 'بنت': 29, 'الصالحة': 30, 'السيدة': 31, 'وسلم': 32, 'الله': 33, 'صلى': 34, 'محمد': 35, 'خديجة': 36, 'اسمها': 37, 'مزاحم': 38, 'واحدة': 39, 'ذكرت': 40, 'ثانس': 41, 'والتي': 42, 'القران': 43, 'سورةالبقرة': 44, 'سورةالكوثر': 45, 'زوجته': 46, 'بخمسة': 47, 'تكبرالنبي': 48, 'تكبره': 49, 'خمسةعشرةعاما': 50, '1الزوجة': 51, 'والزوجة': 52}\n"
     ]
    }
   ],
   "source": [
    "#vocabulaire des mots\n",
    "vocab_list = model.wv.index_to_key\n",
    "\n",
    "#get a dictionary mapping each word to its index in the word vectors \n",
    "vocab_dict = model.wv.key_to_index\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c3d9a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00762661  0.00096393 -0.00696232 -0.00199086  0.00394775  0.00474742\n",
      "  0.0009577   0.00537692 -0.00498367  0.00531021 -0.00700893  0.00259023\n",
      " -0.00867041  0.00405841 -0.00522923 -0.00496967 -0.00129638  0.00554237\n",
      "  0.0060425  -0.00829581  0.00162498 -0.00855524  0.0100941   0.00833923\n",
      " -0.00353571  0.00195746 -0.00140043  0.00653685 -0.00901212  0.00230353\n",
      "  0.00912517  0.00069154  0.00179452 -0.01252209  0.00807056 -0.00456396\n",
      " -0.00319042  0.0029401  -0.00255507  0.0014088   0.00302222 -0.00879073\n",
      " -0.01063224  0.00964895  0.00698767 -0.00897134  0.00321238 -0.00273521\n",
      "  0.00533526 -0.00635506  0.00553327  0.00203747  0.00923805 -0.00371024\n",
      " -0.00177324 -0.00656238 -0.00858157 -0.00909573 -0.0011102  -0.00706715\n",
      "  0.00361045 -0.00762196  0.00504861  0.00236175 -0.00500282  0.00211777\n",
      "  0.01015955  0.01016358 -0.00683612  0.01070335 -0.00505771  0.0072753\n",
      " -0.00132089  0.00394356  0.00483502  0.00615408 -0.00216263  0.00960293\n",
      "  0.00712493 -0.00903849 -0.01148825 -0.00785194  0.00177734 -0.00101912\n",
      " -0.00735566 -0.00927206  0.00926681  0.00207906 -0.00826015 -0.00332166\n",
      "  0.00409956 -0.00481599  0.00618332 -0.00622101  0.0037075  -0.0072018\n",
      "  0.0077224   0.00527961  0.00037494  0.00406395]\n"
     ]
    }
   ],
   "source": [
    "#tester le modèle word2vec 1\n",
    "word=model.wv['الكوثر']\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a28b1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between البقرة and البقرة is: 1.0\n"
     ]
    }
   ],
   "source": [
    "#tester le modèle word2vec 2\n",
    "#calculer la similarité entre 2 mots \n",
    "word1=\"البقرة\"\n",
    "word2=\"البقرة\"\n",
    "\n",
    "similarity = model.wv.similarity(word1,word2)\n",
    "print(f\"Similarity between {word1} and {word2} is: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a9081cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demander à l'utilisateur d'entrer une réponse et un id de question\n",
    "question_id= 9\n",
    "response = \"أطول سورة في القرآن الكريم هي سورة البقرة\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9a95fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['أطول', 'سورة', 'القرآن', 'الكريم', 'سورة', 'البقرة']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokeniser la réponse entrée\n",
    "response_tokens = nltk.word_tokenize(response)\n",
    "\n",
    "# Supprimer les mots d'arrêt de la réponse\n",
    "response_tokens = [w for w in response_tokens if not w in stop_words]\n",
    "\n",
    "# Appliquer le stemming à la réponse\n",
    "response_tokens = [stemmer.stem(word) for word in response_tokens]\n",
    "\n",
    "# Appliquer la lemmatisation à la réponse\n",
    "response_tokens = [lemmatizer.lemmatize(word) for word in response_tokens]\n",
    "\n",
    "# Vectoriser la réponse en utilisant le modèle Word2Vec\n",
    "response_vector = np.mean([model.wv[word] for word in response_tokens if word in model.wv], axis=0)\n",
    "\n",
    "response_vector\n",
    "response_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6b5d5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_existing_answers_vectors(df, question_id, W):\n",
    "\n",
    "    if question_id in df['Question_id'].values:\n",
    "        # Trouver tous les indices correspondants à l'ID de la question\n",
    "        question_indices = df.index[df['Question_id'] == question_id].tolist()\n",
    "\n",
    "        # Extraire les vecteurs de réponse correspondants à partir de la matrice W\n",
    "        existing_answers_vectors = []\n",
    "        for i in question_indices:\n",
    "            existing_answers_vectors.append(W[i])\n",
    "    else:\n",
    "        print(\"L'ID de la question que vous avez fourni est incorrect\")\n",
    "        existing_answers_vectors = None\n",
    "    existing_answers_vectors = np.array(existing_answers_vectors)\n",
    "    return existing_answers_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ead5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Convert lists to strings\n",
    "df['answers'] = df['answers'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the 'answers' column\n",
    "X_answers = tfidf_vectorizer.fit_transform(df['answers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e4ea584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.9362736593165797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Convert 'score' column to numeric\n",
    "df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=['score'])\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(existing_answers_vectors, df[(df['Question_id'] == question_id)]['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the MLP regression model\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Reshape response vector to have shape (1, n)\n",
    "response_vector_reshaped = response_vector.reshape(1, -1)\n",
    "\n",
    "# Predict the score using the MLP regression model\n",
    "score_prediction = mlp_model.predict(response_vector_reshaped)\n",
    "\n",
    "# Print the predicted score\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c65aa2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.8994262319141348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(existing_answers_vectors, df[(df['Question_id'] == question_id)]['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the SVR model\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Reshape response vector to have shape (1, n)\n",
    "response_vector_reshaped = response_vector.reshape(1, -1)\n",
    "\n",
    "# Predict the score using the SVR model\n",
    "score_prediction = svr_model.predict(response_vector_reshaped)\n",
    "\n",
    "# Print the predicted score\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "137c62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Initialize an empty array to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Loop over the existing answer vectors and compute cosine similarity with the response vector\n",
    "for answer_vector in existing_answers_vectors:\n",
    "    cosine_similarity_score = cosine_similarity(response_vector.reshape(1, -1), answer_vector.reshape(1, -1))\n",
    "    cosine_similarities.append(cosine_similarity_score[0][0])\n",
    "\n",
    "# Convert the cosine similarities to a NumPy array\n",
    "cosine_similarities = np.array(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarities with the existing answer vectors\n",
    "combined_features = np.column_stack((existing_answers_vectors, cosine_similarities))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, df[df['Question_id'] == question_id]['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Random Forest Regression model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Reshape response vector to have the same shape as existing answer vectors\n",
    "response_vector_reshaped = np.tile(response_vector, (existing_answers_vectors.shape[0], 1))\n",
    "\n",
    "# Initialize an empty array to store the response cosine similarities\n",
    "response_cosine_similarities = []\n",
    "\n",
    "# Loop over the existing answer vectors and compute cosine similarity with the response vector\n",
    "for answer_vector in existing_answers_vectors:\n",
    "    response_cosine_similarity_score = cosine_similarity(response_vector_reshaped, answer_vector.reshape(1, -1))\n",
    "    response_cosine_similarities.append(response_cosine_similarity_score[0][0])\n",
    "\n",
    "# Convert the response cosine similarities to a NumPy array\n",
    "response_cosine_similarities = np.array(response_cosine_similarities)\n",
    "\n",
    "# Reshape response_cosine_similarities to match the shape of response_vector_reshaped\n",
    "response_cosine_similarities = response_cosine_similarities.reshape(-1, 1)\n",
    "\n",
    "# Concatenate the cosine similarities with the response vector\n",
    "response_combined_features = np.column_stack((response_vector_reshaped, response_cosine_similarities))\n",
    "\n",
    "# Scale the response vector\n",
    "response_combined_features_scaled = scaler.transform(response_combined_features)\n",
    "\n",
    "# Predict the score using the Random Forest Regression model\n",
    "score_prediction = rf_model.predict(response_combined_features_scaled)\n",
    "\n",
    "# Print the predicted score\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e466f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(existing_answers_vectors, df[(df['Question_id'] == question_id)]['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Random Forest Regression model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Reshape response vector to have shape (1, n)\n",
    "response_vector_reshaped = response_vector.reshape(1, -1)\n",
    "\n",
    "# Predict the score using the Random Forest Regression model\n",
    "score_prediction = rf_model.predict(response_vector_reshaped)\n",
    "\n",
    "# Print the predicted score\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9340eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.9999955731001854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(existing_answers_vectors, df[(df['Question_id'] == question_id)]['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Gradient Boosted Regression model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Reshape response vector to have shape (1, n)\n",
    "response_vector_reshaped = response_vector.reshape(1, -1)\n",
    "\n",
    "# Predict the score using the Gradient Boosted Regression model\n",
    "score_prediction = gb_model.predict(response_vector_reshaped)\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5c446d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_existing_answers_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m existing_answers_vectors \u001b[38;5;241m=\u001b[39m find_existing_answers_vectors(df, question_id, W)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize an empty array to store the cosine similarities\u001b[39;00m\n\u001b[0;32m     10\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_existing_answers_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "existing_answers_vectors = find_existing_answers_vectors(df, question_id, W)\n",
    "\n",
    "# Initialize an empty array to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Loop over the existing answer vectors and compute cosine similarity with the response vector\n",
    "for answer_vector in existing_answers_vectors:\n",
    "    cosine_similarity_score = cosine_similarity(response_vector.reshape(1, -1), answer_vector.reshape(1, -1))\n",
    "    cosine_similarities.append(cosine_similarity_score[0][0])\n",
    "\n",
    "# Convert the cosine similarities to a NumPy array\n",
    "cosine_similarities = np.array(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarities with the existing answer vectors\n",
    "combined_features = np.column_stack((existing_answers_vectors, cosine_similarities))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, df[df['Question_id'] == question_id]['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale input data to [0, 1] range\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the GradientBoostingRegressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Reshape response vector to have the same shape as existing answer vectors\n",
    "response_vector_reshaped = np.tile(response_vector, (existing_answers_vectors.shape[0], 1))\n",
    "\n",
    "# Initialize an empty array to store the response cosine similarities\n",
    "response_cosine_similarities = []\n",
    "\n",
    "# Loop over the existing answer vectors and compute cosine similarity with the response vector\n",
    "for answer_vector in existing_answers_vectors:\n",
    "    response_cosine_similarity_score = cosine_similarity(response_vector_reshaped, answer_vector.reshape(1, -1))\n",
    "    response_cosine_similarities.append(response_cosine_similarity_score[0][0])\n",
    "\n",
    "# Convert the response cosine similarities to a NumPy array\n",
    "response_cosine_similarities = np.array(response_cosine_similarities)\n",
    "\n",
    "# Reshape response_cosine_similarities to match the shape of response_vector_reshaped\n",
    "response_cosine_similarities = response_cosine_similarities.reshape(-1, 1)\n",
    "\n",
    "# Concatenate the cosine similarities with the response vector\n",
    "response_combined_features = np.column_stack((response_vector_reshaped, response_cosine_similarities))\n",
    "\n",
    "# Scale the response vector\n",
    "response_combined_features_scaled = scaler.transform(response_combined_features)\n",
    "\n",
    "# Predict the score using the GradientBoostingRegressor model\n",
    "score_prediction = gb_model.predict(response_combined_features_scaled)\n",
    "\n",
    "# Print the predicted score\n",
    "print(\"Predicted score:\", score_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e13677c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Transformer' from 'tensorflow.keras.layers' (C:\\Users\\damia\\anaconda3\\Lib\\site-packages\\keras\\api\\_v2\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding, LSTM, Dense, Bidirectional, Transformer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Transformer' from 'tensorflow.keras.layers' (C:\\Users\\damia\\anaconda3\\Lib\\site-packages\\keras\\api\\_v2\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(W, df['score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training - LSTM\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=len(vocab_list)+1, output_dim=max_len, input_length=max_len),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Training - Transformer\n",
    "model_transformer = Sequential([\n",
    "    Transformer(model_dim=max_len, num_heads=4, num_transformer_blocks=2, mlp_dim=32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_transformer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_transformer.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Text Generation using BERT (Fine-Tuning) - You can use transformers library\n",
    "# For simplicity, let's use a placeholder function for fine-tuning BERT\n",
    "\n",
    "def fine_tune_bert(data):\n",
    "    # Implement fine-tuning logic using transformers library\n",
    "    # Example: https://huggingface.co/transformers/main_classes/configuration.html\n",
    "    pass\n",
    "\n",
    "# Evaluation of Models\n",
    "# Evaluate LSTM model\n",
    "lstm_eval = model_lstm.evaluate(X_test, y_test)\n",
    "print(\"LSTM Evaluation:\", lstm_eval)\n",
    "\n",
    "# Evaluate Transformer model\n",
    "transformer_eval = model_transformer.evaluate(X_test, y_test)\n",
    "print(\"Transformer Evaluation:\", transformer_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e9941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
